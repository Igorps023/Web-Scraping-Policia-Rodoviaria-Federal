# %%
"""
Codigo dedicado para a obtencao do encoding existente nos arquivos .zip (somente 2019 em diante)
"""
import pandas as pd
from pandas.errors import ParserError  # Import ParserError
import chardet
from chardet.universaldetector import UniversalDetector
import os
from pathlib import Path
import zipfile
from IPython.display import display, HTML

#Source
path = Path('./Arquivos/Multas')
caminho_completo = path=path.resolve()

#Funcoes
def filtered_folder_pattern(dir_abs_path, corte_inicial, corte_final):
    """
    Recebe um diretorio, lista os arquivos nesse diretorio, e filtra os arquivos (nesse caso, ano)
    """
    lista = os.listdir(dir_abs_path)
    lista_teste = [j for j in lista if j.split('_')[1].split('.')[0].isdigit() and int(j.split('_')[1].split('.')[0]) >= corte_inicial and int(j.split('_')[1].split('.')[0]) <= corte_final]
    return sorted(lista_teste)

def save_encoding_info(lista_de_entrada):
    """
    Salva o tipo de encoding utilizado no arquivo em um dicionario
    """
    encodings = []
    for archives in lista_de_entrada:
        if archives.endswith('.zip') or archives.endswith('.rar'):
            with zipfile.ZipFile(os.path.join(caminho_completo, archives), 'r') as zip_ref:
                #Get a list of all files and directories inside the ZIP file
                contents = zip_ref.infolist()
                for item in contents:
                    #Is not a directory
                    if item.filename.endswith('.csv') and not item.is_dir(): 
                        #Start Detector
                        detector = UniversalDetector()
                        detector.reset()
                        with zip_ref.open(item.filename) as file:
                            chunk_size = 10 * 1024  # 1 MB
                            chunk = file.read(chunk_size)    
                            while chunk:
                                detector.feed(chunk)
                                if detector.done:
                                    break
                                detector.close()
                                #print(f"File: {item.filename} | {detector.result['encoding']} | {detector.result['confidence']}")
                                encodings.append(
                                    {
                                    "filename" : item.filename,
                                    "encoding" : detector.result['encoding'],
                                    "confidence" : detector.result['confidence'],
                                    }
                                )

    return encodings

def read_files_then_parquet(lista_de_entrada, output_path_parquet):
    """
    Read the .csv files inside the .zip files
    Applies the encoding list that was generated by the 'encod_list' for reading the files correctly
    Converts them to parquet
    Saves them on another directory
    """
    logs_list = []
    for archives in lista_de_entrada:
        if archives.endswith('.zip') or archives.endswith('.rar'):
            with zipfile.ZipFile(os.path.join(caminho_completo, archives), 'r') as zip_ref:
                #Get a list of all files and directories inside the ZIP file
                contents = zip_ref.infolist()
                for item in contents:
                    if item.filename.endswith('.csv') and not item.is_dir(): #Is not a directory
                        #Encoding info related to specific files
                        encoding_info = next((x for x in encod_list if x['filename'] == item.filename), None)
                        if encoding_info:
                            with zip_ref.open(item.filename) as file:
                                
                                df = pd.read_csv(file, encoding=encoding_info['encoding'], sep=';', dtype='object')
                                try:
                                    df.to_parquet(output_path_parquet+'/'+item.filename.split('.')[0]+'.parquet')
                                    print(output_path_parquet+'/'+item.filename.split('.')[0]+'.parquet')
                                    logs_list.append({"File": item.filename, "Format Converted": "Parquet"})
                                except:
                                    try:
                                        df.to_parquet(output_path_parquet+'/'+item.filename.split('.')[0].split('/')[1]+'.parquet')
                                        print(output_path_parquet+'/'+item.filename.split('.')[0].split('/')[1]+'.parquet')
                                        logs_list.append({"File": item.filename, "Format Converted": "Parquet"})
                                        #print(f'Dealing with files with dir, converted and saved! | {item.filename}')
                                    except Exception as e:
                                        print(f'Error! {str(e)}')
                        else:
                            print(f'Error: {item}')
    return logs_list
# %%
# Executa as funcoes
lista_arquivos = filtered_folder_pattern(caminho_completo, 2019)
encod_list = save_encoding_info(lista_arquivos)
logs_list = read_files_then_parquet(lista_arquivos, str(Path('./Arquivos/ETL_2019_em_diante/Parquet/').resolve()) )